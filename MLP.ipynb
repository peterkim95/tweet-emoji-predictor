{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"sent_corpus.csv\", \"r\") as sent_file:\n",
    "    lines = sent_file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 1.89 s, total: 5.14 s\n",
      "Wall time: 6.33 s\n",
      "CPU times: user 4.48 s, sys: 157 ms, total: 4.64 s\n",
      "Wall time: 4.65 s\n",
      "CPU times: user 377 ms, sys: 52.4 ms, total: 429 ms\n",
      "Wall time: 475 ms\n",
      "CPU times: user 4.82 s, sys: 834 ms, total: 5.65 s\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%time rows = [line.split(\",\") for line in lines if line]\n",
    "%time rows = [row[:3] + [\",\".join(row[3:])] for row in rows]\n",
    "# remove document start character \n",
    "rows[0][0] = rows[0][0][1:]\n",
    "\n",
    "sentDf_cols = ['ItemID', 'Sentiment', 'SentimentSource', 'SentimentText']\n",
    "\n",
    "\n",
    "%time sentDf_a = pd.DataFrame(rows[1:],columns=sentDf_cols)\n",
    "\n",
    "#print(sentDf)\n",
    "\n",
    "sentDf_a[[\"ItemID\",\"Sentiment\"]] = sentDf_a[[\"ItemID\",\"Sentiment\"]].astype(int)\n",
    "%time sentDf_a[\"SentimentText\"] = sentDf_a[\"SentimentText\"].apply(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 11 s, total: 1min 47s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "%time w2vM = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "dim = 300\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 2.53 s, total: 1min 24s\n",
      "Wall time: 38.5 s\n"
     ]
    }
   ],
   "source": [
    "%time w2vM = gensim.models.Word2Vec(sentDf[\"SentimentText\"])\n",
    "dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+\"/fullData/\"\n",
    "with open(path+\"us_train.labels\", \"r\") as labels_file:\n",
    "    lines = labels_file.read().split(\"\\n\")\n",
    "    \n",
    "labels = pd.DataFrame(lines[:], columns=['SentimentLabels'])\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 952 ms, sys: 28.4 ms, total: 981 ms\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+\"/fullData/\"\n",
    "with open(path+\"us_train.text\", \"r\") as tweet_text_file:\n",
    "    lines = tweet_text_file.read().split(\"\\n\")\n",
    "    \n",
    "counter = 0\n",
    "for line in lines:\n",
    "    if(counter == 100):\n",
    "        break\n",
    "#    print(line)\n",
    "    counter += 1\n",
    "    \n",
    "sentDf = pd.DataFrame(lines[:], columns=['SentimentText'])\n",
    "%time sentDf[\"SentimentText\"] = sentDf[\"SentimentText\"].apply(lambda text: text.split())\n",
    "#print(sentDf[1:])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples to aggregate\n",
    "Ns = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 1.97 s, total: 12.3 s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MEAN AGGREGATION\n",
    "tvecs = np.array([np.array([w2vM[t] if t in w2vM\n",
    "                                else np.zeros((dim,))\n",
    "                            for t in twt]).mean(axis=0)\n",
    "                 for twt in sentDf['SentimentText'][:Ns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 17  0 ...,  9  9  6]\n",
      "[[-0.03525391  0.06650391  0.06716309 ..., -0.05820313 -0.02873535\n",
      "   0.03405762]\n",
      " [-0.00695801  0.06316584 -0.05490945 ..., -0.06491921  0.00937722\n",
      "  -0.03728693]\n",
      " [-0.03508301 -0.05007324 -0.04908447 ..., -0.0609375  -0.00522461\n",
      "   0.06296082]\n",
      " ..., \n",
      " [ 0.02618408  0.02658081  0.0098877  ..., -0.05737305  0.02505493\n",
      "   0.06640625]\n",
      " [-0.00427246  0.09061686  0.02342394 ..., -0.0339951   0.05254449\n",
      "   0.02824571]\n",
      " [ 0.00064087  0.01641846  0.03424072 ..., -0.02520752  0.01345825\n",
      "   0.00135803]]\n"
     ]
    }
   ],
   "source": [
    "# number of samples to train on\n",
    "N = int(1e5)\n",
    "X = tvecs[:N]\n",
    "y_pre = labels['SentimentLabels'][:N].values\n",
    "\n",
    "y = np.array(y_pre).astype(np.int)\n",
    "\n",
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate test/train split\n",
    "ratio = 0.8\n",
    "tidx = np.random.rand(N) < ratio\n",
    "pidx = ~tidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import ensemble,svm,neural_network,discriminant_analysis\n",
    "from sklearn.metrics import roc_curve,auc,precision_recall_curve\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 59s, sys: 28.9 s, total: 6min 28s\n",
      "Wall time: 4min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_config = (100,)\n",
    "\n",
    "mlp = sklearn.neural_network.MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes= hidden_layer_config, learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "\n",
    "\n",
    "%time mlp.fit(X[tidx],y[tidx])\n",
    "\n",
    "#51% is baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 17  0 ...,  0  1  1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_pre = mlp.predict(X[tidx])\n",
    "\n",
    "y_pred = np.array(y_pred_pre).astype(np.int)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48138\n",
      "0.48138\n"
     ]
    }
   ],
   "source": [
    "num_same = 0\n",
    "\n",
    "for i in y:\n",
    "    if(y_pred[i] == y[i]):\n",
    "#        print(\"y pred: \" + str(y_pred[i]) +\" y: \" + str(y[i]))\n",
    "        num_same += 1\n",
    "    \n",
    "print(num_same)    \n",
    "accuracy = float(num_same) / y.size\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data is not binary and pos_label is not specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-559436b206c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \"\"\"\n\u001b[1;32m    509\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 510\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    317\u001b[0m              \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m              np.array_equal(classes, [1]))):\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data is not binary and pos_label is not specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data is not binary and pos_label is not specified"
     ]
    }
   ],
   "source": [
    "n_classes = 20\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y[:i], y_pred[:i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
