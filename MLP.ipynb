{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/us_train.text\", \"r\") as sent_file:\n",
    "    lines = sent_file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 ms, sys: 14.8 ms, total: 55.8 ms\n",
      "Wall time: 47.8 ms\n",
      "CPU times: user 55 ms, sys: 17.3 ms, total: 72.3 ms\n",
      "Wall time: 60.3 ms\n",
      "CPU times: user 8.66 ms, sys: 1.53 ms, total: 10.2 ms\n",
      "Wall time: 12 ms\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for long() with base 10: 'glam on @user yesterday for #kcon makeup using @user in #featherette'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5daf66887b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(sentDf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msentDf_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ItemID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentDf_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ItemID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time sentDf_a[\"SentimentText\"] = sentDf_a[\"SentimentText\"].apply(lambda text: text.split())'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/util/_decorators.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 3410\u001b[0;31m                                      **kwargs)\n\u001b[0m\u001b[1;32m   3411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3091\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 471\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, klass, mgr, raise_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/pandas/core/dtypes/cast.pyc\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"datetime64\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"timedelta64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/util.pxd\u001b[0m in \u001b[0;36mutil.set_value_at_unsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for long() with base 10: 'glam on @user yesterday for #kcon makeup using @user in #featherette'"
     ]
    }
   ],
   "source": [
    "%time rows = [line.split(\",\") for line in lines if line]\n",
    "%time rows = [row[:3] + [\",\".join(row[3:])] for row in rows]\n",
    "# remove document start character \n",
    "rows[0][0] = rows[0][0][1:]\n",
    "\n",
    "sentDf_cols = ['ItemID', 'Sentiment', 'SentimentSource', 'SentimentText']\n",
    "\n",
    "\n",
    "%time sentDf_a = pd.DataFrame(rows[1:],columns=sentDf_cols)\n",
    "\n",
    "#print(sentDf)\n",
    "\n",
    "sentDf_a[[\"ItemID\",\"Sentiment\"]] = sentDf_a[[\"ItemID\",\"Sentiment\"]].astype(int)\n",
    "%time sentDf_a[\"SentimentText\"] = sentDf_a[\"SentimentText\"].apply(lambda text: text.split())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+\"/data/\"\n",
    "with open(path+\"us_train.text\", \"r\") as tweet_text_file:\n",
    "    lines = tweet_text_file.read().split(\"\\n\")\n",
    "    \n",
    "\n",
    "    \n",
    "sentDf = pd.DataFrame(lines[:], columns=['SentimentText'])\n",
    "%time sentDf[\"SentimentText\"] = sentDf[\"SentimentText\"].apply(lambda text: text.split())\n",
    "#print(sentDf[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 7.08 s, total: 1min 30s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "%time w2vM = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "dim = 300\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 1.85 s, total: 2min 11s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "\n",
    "dim = 300\n",
    "%time w2vM = gensim.models.Word2Vec(sentDf[\"SentimentText\"], size=dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()+\"/data/\"\n",
    "with open(path+\"us_train.labels\", \"r\") as labels_file:\n",
    "    lines_test = labels_file.read().split(\"\\n\")\n",
    "    \n",
    "with open(path+\"us_trial.labels\", \"r\") as labels_file:\n",
    "    lines_trial = labels_file.read().split(\"\\n\")\n",
    "    \n",
    "labels_train = pd.DataFrame(lines_test[:], columns=['SentimentLabels'])\n",
    "labels_test = pd.DataFrame(lines_trial[:], columns=['SentimentLabels'])\n",
    "#print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 676 ms, sys: 106 ms, total: 782 ms\n",
      "Wall time: 801 ms\n",
      "CPU times: user 64.8 ms, sys: 6.67 ms, total: 71.4 ms\n",
      "Wall time: 71.7 ms\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+\"/data/\"\n",
    "with open(path+\"us_train.text\", \"r\") as tweet_text_file:\n",
    "    lines = tweet_text_file.read().split(\"\\n\")\n",
    "    \n",
    "\n",
    "    \n",
    "sentDf_train = pd.DataFrame(lines[:], columns=['SentimentText'])\n",
    "%time sentDf_train[\"SentimentText\"] = sentDf_train[\"SentimentText\"].apply(lambda text: text.split())\n",
    "#print(sentDf[1:])\n",
    "    \n",
    "with open(path+\"us_trial.text\", \"r\") as tweet_text_file:\n",
    "    lines = tweet_text_file.read().split(\"\\n\")\n",
    "\n",
    "    \n",
    "sentDf_test = pd.DataFrame(lines[:], columns=['SentimentText'])\n",
    "%time sentDf_test[\"SentimentText\"] = sentDf_test[\"SentimentText\"].apply(lambda text: text.split())\n",
    "#print(sentDf[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of samples to aggregate\n",
    "N_train = labels_train.size#int(1e5)\n",
    "N_test = labels_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.2 s, sys: 2.34 s, total: 38.5 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MEAN AGGREGATION\n",
    "tvecs_train = np.array([np.array([w2vM[t] if t in w2vM\n",
    "                                else np.zeros((dim,))\n",
    "                            for t in twt]).mean(axis=0)\n",
    "                 for twt in sentDf_train['SentimentText'][:N_train]])\n",
    "\n",
    "\n",
    "tvecs_test = np.array([np.array([w2vM[t] if t in w2vM\n",
    "                                else np.zeros((dim,))\n",
    "                            for t in twt]).mean(axis=0)\n",
    "                 for twt in sentDf_test['SentimentText'][:N_test]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '17' '0' ..., '11' '19' '14']\n",
      "['0' '7' '11' ..., '11' '0' '9']\n",
      "[ 0  7 11 ..., 11  0  9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = tvecs_train[:N_train]\n",
    "X_test = tvecs_test[:N_test]\n",
    "\n",
    "print(labels_train['SentimentLabels'][:N_train].values)\n",
    "print(labels_test['SentimentLabels'][:N_test].values)\n",
    "\n",
    "y_pre_train = labels_train['SentimentLabels'][:N_train].values\n",
    "y_pre_test = labels_test['SentimentLabels'][:N_test].values\n",
    "\n",
    "y_train = np.array(y_pre_train).astype(np.int)\n",
    "y_test = np.array(y_pre_test).astype(np.int)\n",
    "\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d566041ea249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generate test/train split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mtidx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "# generate test/train split\n",
    "ratio = 0.8\n",
    "tidx = np.random.rand(N) < ratio\n",
    "pidx = ~tidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import ensemble,svm,neural_network,discriminant_analysis\n",
    "from sklearn.metrics import roc_curve,auc,precision_recall_curve\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 s, sys: 80.7 ms, total: 4.16 s\n",
      "Wall time: 4.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier()\n",
    "rf.max_depth = 5\n",
    "\n",
    "%time rf.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 19s, sys: 1min 47s, total: 42min 6s\n",
      "Wall time: 25min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(140,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=400, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = 140\n",
    "max_iters = 400\n",
    "hidden_layer_config = (num_nodes,)\n",
    "\n",
    "mlp = sklearn.neural_network.MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes= hidden_layer_config, learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=max_iters, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "\n",
    "\n",
    "#fit to training data\n",
    "#%time mlp.fit(X[tidx],y_train[tidx])\n",
    "%time mlp.fit(X_train, y_train)\n",
    "\n",
    "#51% is baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy(model, X_train, X_test, y_train, y_test):\n",
    "    y_pred_pre_train = model.predict(X_train)\n",
    "    y_pred_train = np.array(y_pred_pre_train).astype(np.int)\n",
    "\n",
    "    y_pred_pre_test = model.predict(X_test)\n",
    "    y_pred_test = np.array(y_pred_pre_test).astype(np.int)\n",
    "\n",
    "    num_same_train = 0\n",
    "    num_same_test = 0\n",
    "\n",
    "    for i in y_pred_train:\n",
    "        if(y_pred_train[i] == y_train[i]):\n",
    "            num_same_train += 1\n",
    "    for i in y_pred_test:\n",
    "        if(y_pred_test[i] == y_test[i]):\n",
    "            num_same_test += 1\n",
    "\n",
    "#    print(num_same_train)    \n",
    " #   print(num_same_test)\n",
    "\n",
    "    accuracy_train = float(num_same_train) / y_train.size\n",
    "    accuracy_test = float(num_same_test) / y_test.size\n",
    "    \n",
    "    return accuracy_train, accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn stats... \n",
      "F1 score: 0.195525138436\n",
      "training accuracy: 0.856217277759\n",
      "test accuracy: 0.33478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "import pickle\n",
    "print(\"nn stats... \")\n",
    "\n",
    "#y_train and y_test are ground truth\n",
    "nn_acc_train, nn_acc_test = getAccuracy(mlp, X_train, X_test, y_train, y_test)\n",
    "y_pred_pre = mlp.predict(X_test)\n",
    "y_pred_test = np.array(y_pred_pre).astype(np.int)\n",
    "\n",
    "\n",
    "nn_f1 = sklearn.metrics.f1_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "\n",
    "print(\"F1 score: \" +str(nn_f1))\n",
    "print(\"training accuracy: \" + str(nn_acc_train))\n",
    "print(\"test accuracy: \" + str(nn_acc_test))\n",
    "if(nn_f1 > 0.37):\n",
    "    print(\"Good model. Saving...\")\n",
    "    filename_acc = str(nn_acc_test)[2:4]\n",
    "    f1 = str(nn_f1)[2:4]\n",
    "    filename = \"model_acc\"+filename_acc+\"hl\"+str(num_nodes)+\"f\"+f1+\".pkl\"\n",
    " #   joblib.dump(mlp, filename)\n",
    "    pickle.dump(mlp, open(filename, 'wb'))\n",
    "    \n",
    "    print(\"model saved\")\n",
    "\n",
    "#print(\"rf stats... \")\n",
    "#rf_acc_train, rf_acc_test = getAccuracy(rf, X_train, X_test, y_train, y_test)\n",
    "#print(\"training accuracy: \" + str(rf_acc_train))\n",
    "#print(\"test accuracy: \" + str(rf_acc_test))\n",
    "\n",
    "#100 hidden layer\n",
    "#training accuracy: 0.870539291601\n",
    "#test accuracy: 0.77532\n",
    "\n",
    "#140 hidden layer\n",
    "#training accuracy: 0.852538685422\n",
    "#test accuracy: 0.32128\n",
    "\n",
    "#100 2 hidden layers\n",
    "#F1 = 48.761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.541832570074\n",
      "test accuracy: 0.86106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "filename = \"models/model_acc86hl140f65\"\n",
    "full_fn = filename+\".pkl\"\n",
    "\n",
    "loaded_model = joblib.load(full_fn)\n",
    "nn_acc_train, nn_acc_test = getAccuracy(loaded_model, X_train, X_test, y_train, y_test)\n",
    "print(\"training accuracy: \" + str(nn_acc_train))\n",
    "print(\"test accuracy: \" + str(nn_acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  7 11 ..., 10  9  0]\n",
      "50000\n",
      "0.195525138436\n"
     ]
    }
   ],
   "source": [
    "#loaded_model = mlp\n",
    "import sklearn \n",
    "\n",
    "loaded_model = mlp\n",
    "y_pred_pre = loaded_model.predict(X_test)\n",
    "y_pred_test = np.array(y_pred_pre).astype(np.int)\n",
    "\n",
    "print(y_pred_test)\n",
    "print(y_pred_test.size)\n",
    "f1 = sklearn.metrics.f1_score(y_test, y_pred_test, average='macro')\n",
    "print(f1)\n",
    "np.savetxt('english.output2.txt', y_pred_test, fmt='%i')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 20\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y[:i], y_pred[:i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
